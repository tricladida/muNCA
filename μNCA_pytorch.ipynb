{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Î¼NCA_pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR8YNR-g9JXA",
        "cellView": "form"
      },
      "source": [
        "#@title imports, helpers \n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "!pip install -q --progress-bar off einops\n",
        "from einops import rearrange\n",
        "!pip install -q --progress-bar off pykeops[colab] geomloss\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from functools import partial\n",
        "\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "\n",
        "def imread(url, max_size=None, mode=None):\n",
        "  if url.startswith(('http:', 'https:')):\n",
        "    # wikimedia requires a user agent\n",
        "    headers = {\n",
        "      \"User-Agent\": \"Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0\"\n",
        "    }\n",
        "    r = requests.get(url, headers=headers)\n",
        "    f = io.BytesIO(r.content)\n",
        "  else:\n",
        "    f = url\n",
        "  img = PIL.Image.open(f)\n",
        "  if max_size is not None:\n",
        "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  if mode is not None:\n",
        "    img = img.convert(mode)\n",
        "  img = np.float32(img)/255.0\n",
        "  return img\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename='_autoplay.mp4', fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()\n",
        "    if self.params['filename'] == '_autoplay.mp4':\n",
        "      self.show()\n",
        "\n",
        "  def show(self, **kw):\n",
        "      self.close()\n",
        "      fn = self.params['filename']\n",
        "      display(mvp.ipython_display(fn, **kw))\n",
        "\n",
        "class LoopWriter(VideoWriter):\n",
        "  def __init__(self, *a, fade_len=1.0, **kw):\n",
        "    super().__init__(*a, **kw)\n",
        "    self._intro = []\n",
        "    self._outro = []\n",
        "    self.fade_len = int(fade_len*self.params['fps'])\n",
        "\n",
        "  def add(self, img):\n",
        "    if len(self._intro) < self.fade_len:\n",
        "      self._intro.append(img)\n",
        "      return\n",
        "    self._outro.append(img)\n",
        "    if len(self._outro) > self.fade_len:\n",
        "      super().add(self._outro.pop(0))\n",
        "  \n",
        "  def close(self):\n",
        "    for t in np.linspace(0, 1, len(self._intro)):\n",
        "      img = self._intro.pop(0)*t + self._outro.pop(0)*(1.0-t)\n",
        "      super().add(img)\n",
        "    super().close()\n",
        "\n",
        "\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "def to_nchw(img):\n",
        "  img = torch.as_tensor(img)\n",
        "  if len(img.shape) == 3:\n",
        "    img = img[None,...]\n",
        "  return img.permute(0, 3, 1, 2)\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqmv9w5tPQB",
        "cellView": "form"
      },
      "source": [
        "#@title VGG16-based feature extraction \n",
        "vgg16 = models.vgg16(pretrained=True).features\n",
        "\n",
        "def calc_styles_vgg(imgs):\n",
        "  style_layers = [1, 6, 11, 18, 25]  \n",
        "  mean = torch.tensor([0.485, 0.456, 0.406])[:,None,None]\n",
        "  std = torch.tensor([0.229, 0.224, 0.225])[:,None,None]\n",
        "  x = (imgs-mean) / std\n",
        "  grams = []\n",
        "  for i, layer in enumerate(vgg16[:max(style_layers)+1]):\n",
        "    x = layer(x)\n",
        "    if i in style_layers:\n",
        "      h, w = x.shape[-2:]\n",
        "      y = x.clone()  # workaround for pytorch in-place modification bug(?)\n",
        "      gram = torch.einsum('bchw, bdhw -> bcd', y, y) / (h*w)\n",
        "      grams.append(gram)\n",
        "  return grams\n",
        "\n",
        "def create_vgg_loss(target_img):\n",
        "  target_style = calc_styles_vgg(target_img)\n",
        "  def loss_f(imgs):\n",
        "    xs = calc_styles_vgg(imgs)\n",
        "    loss = 0.0\n",
        "    for x, y in zip(xs, target_style):\n",
        "      loss = loss + (x-y).square().mean()\n",
        "    return loss\n",
        "  return loss_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "YdWeJ1HydeZ7"
      },
      "source": [
        "# OT loss \n",
        "from geomloss import SamplesLoss\n",
        "from torchvision.transforms.functional_tensor import gaussian_blur\n",
        "\n",
        "def calc_styles_ot(img, ksize, leveln, show=False):\n",
        "  levels = []\n",
        "  for i in range(leveln):\n",
        "    blured = gaussian_blur(img, [5, 5], [1, 1])\n",
        "    unsharp = img + (img-blured)*2.0\n",
        "    if show:\n",
        "      imshow(unsharp[0].permute(1, 2, 0).cpu())\n",
        "    win = F.unfold(unsharp, ksize).permute(0, 2, 1).contiguous()\n",
        "    levels.append(win)\n",
        "    if i<leveln-1:\n",
        "      img = blured[:,:,::2,::2]\n",
        "  return levels\n",
        " \n",
        "opt_f = SamplesLoss()\n",
        "\n",
        "def subsample(x, n=2048):\n",
        "  if x.shape[1]>n:\n",
        "    idx = torch.multinomial(torch.ones(x.shape[1]), n)\n",
        "    x = x[:,idx]\n",
        "  return x\n",
        "\n",
        "def create_ot_loss(target_img, ksize=5, leveln=5, show=False):\n",
        "  target_style = calc_styles_ot(target_img, ksize, leveln, show)\n",
        "  def loss_f(imgs):\n",
        "    xs = calc_styles_ot(imgs, ksize, leveln)\n",
        "    loss = 0.0\n",
        "    for x, y in zip(xs, target_style):\n",
        "      x, y = subsample(x, 1024), subsample(y, 1024*2)\n",
        "      y = y.repeat(x.shape[0], 1, 1)\n",
        "      loss += opt_f(x, y).mean()\n",
        "    return loss\n",
        "  return loss_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewXnAPrbHx0-"
      },
      "source": [
        "# Î¼NCA \n",
        "side = torch.tensor([[0.0, 0.0,0.0], [2.0,-2.0,0.0], [0.0, 0.0,0.0]]) \n",
        "sobel_x = torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]]) \n",
        "lap = torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])\n",
        "\n",
        "# filters = [lap]*2+[sobel_x]*1+[sobel_x.T]*1  # 68 params\n",
        "# filters = [lap]*2+[sobel_x]*2+[sobel_x.T]*2 # 150 params\n",
        "# filters = [lap]*4+[sobel_x]*2+[sobel_x.T]*2  # 264 params\n",
        "filters = [lap]*4+[sobel_x]*4+[sobel_x.T]*4  # 588 params\n",
        "\n",
        "filters = torch.stack(filters)[:,None]\n",
        "CHN = len(filters)\n",
        "\n",
        "class CA(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w = torch.nn.Parameter(torch.randn(CHN, 4*CHN+1, 1, 1)*1e-3)\n",
        "\n",
        "  def to_rgb(self, x):\n",
        "    return x[...,:3,:,:]+0.5\n",
        "\n",
        "  def forward(self, x, update_rate=1.0):\n",
        "    y = torch.nn.functional.pad(x, [1, 1, 1, 1], 'circular')\n",
        "    y = torch.nn.functional.conv2d(y, filters, groups=y.shape[1])\n",
        "    y = torch.cat([x, y], 1)\n",
        "    y = y = torch.cat([y, y.abs()], 1)\n",
        "    #y = torch.cat([y.relu(), -(-y).relu()], 1)\n",
        "    w, b = self.w[:,:-1], self.w[:,-1,0,0]\n",
        "    y = torch.nn.functional.conv2d(y, w, b)\n",
        "    if update_rate<1.0:\n",
        "      y *= (torch.rand(*y.shape)+update_rate).floor()\n",
        "    return x+y, y\n",
        "    \n",
        "def seed_f(n, sz=128):\n",
        "  return torch.rand(n, CHN, sz, sz)-0.5\n",
        "\n",
        "ca = CA()\n",
        "print('param count:', sum(p.numel() for p in ca.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NNHH6fSsLvv"
      },
      "source": [
        "# target\n",
        "url = 'https://www.robots.ox.ac.uk/~vgg/data/dtd/thumbs/bubbly/bubbly_0101.jpg'\n",
        "\n",
        "with torch.no_grad():\n",
        "  style_img = imread(url, max_size=128)\n",
        "  texture_loss_f = create_ot_loss(to_nchw(style_img))\n",
        "imshow(style_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cd1uMD3cZw3"
      },
      "source": [
        "#@title setup training\n",
        "ca = CA() \n",
        "opt = torch.optim.Adam(ca.parameters(), 1e-3)\n",
        "lr_sched = torch.optim.lr_scheduler.MultiStepLR(opt, [1000, 4000], 0.3)\n",
        "loss_log = []\n",
        "with torch.no_grad():\n",
        "  pool = seed_f(256)\n",
        "!rm *.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0GYHC3U-cd1"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pxjdESnYlIC"
      },
      "source": [
        "#@title training loop {vertical-output: true}\n",
        "\n",
        "def loss_f(x):\n",
        "  loss = texture_loss_f(ca.to_rgb(x))\n",
        "  reg = (x-x.clamp(-1.0, 1.0)).square().sum()\n",
        "  total_loss = loss + reg\n",
        "  return total_loss, loss\n",
        "\n",
        "best_long_loss = np.inf\n",
        "best_long_step = 0\n",
        "\n",
        "for i in range(10000):\n",
        "  batch_idx = np.random.choice(len(pool), 4, replace=False)\n",
        "  x = pool[batch_idx]\n",
        "  if i%8 == 0:   \n",
        "    x[:1] = seed_f(1)\n",
        "  step_n = np.random.randint(32, 128)\n",
        "  torch.autograd.set_grad_enabled(True)\n",
        "  for _ in range(step_n):\n",
        "    x, dx = ca(x)\n",
        "    x.register_hook(partial(F.normalize, dim=[1,2,3]))\n",
        "  total_loss, loss = loss_f(x)\n",
        "  total_loss.backward()\n",
        "  with torch.no_grad():\n",
        "    for p in ca.parameters():\n",
        "      p.grad /= (p.grad.norm()+1e-8)   # normalize gradients \n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    lr_sched.step()\n",
        "    pool[batch_idx] = x                # update pool\n",
        "    \n",
        "    loss_log.append(loss.item())\n",
        "    if i%64==0:\n",
        "      clear_output(True)\n",
        "\n",
        "      min_loss = np.min(loss_log)\n",
        "      pl.plot(loss_log, '.', alpha=0.1)\n",
        "      if min_loss > 0.0:\n",
        "        pl.yscale('log')\n",
        "      pl.ylim(min_loss, loss_log[len(loss_log)//5])\n",
        "      pl.show()\n",
        "      imgs = ca.to_rgb(x).permute([0, 2, 3, 1]).cpu()\n",
        "      imshow(np.hstack(imgs))\n",
        "      pl.show()\n",
        "      p = ca.w.cpu()[:,:,0,0]\n",
        "      vis = torch.stack([(-p).relu(), p.relu(), 0.0*p], -1)\n",
        "      vis *= 1.0/vis.max()\n",
        "      imshow(zoom(vis))\n",
        "      pl.show()\n",
        "\n",
        "      # show long-term behaviour\n",
        "      x = seed_f(1)\n",
        "      for _ in range(3000):\n",
        "        x, _ = ca(x)\n",
        "      img = ca.to_rgb(x)[0].permute(1, 2, 0).cpu()\n",
        "      imshow(img)\n",
        "      _, long_loss = loss_f(x.clip(-1, 1))\n",
        "      if long_loss<best_long_loss and len(loss_log)-best_long_step > 100:\n",
        "        torch.save(ca, 'ca_%05d.pt'%len(loss_log))\n",
        "        best_long_loss = long_loss\n",
        "        best_long_step = len(loss_log)\n",
        "\n",
        "    if i%10 == 0:\n",
        "      print('\\rstep_n:', len(loss_log),\n",
        "        ' loss:', loss.item(), \n",
        "        ' lr:', lr_sched.get_lr()[0], end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8T3OJ4nabjB"
      },
      "source": [
        "# Î¼NCA pattern after 1000 steps \n",
        "with torch.no_grad():\n",
        "  x = seed_f(1, 128)\n",
        "  ca1 = torch.load('ca_%05d.pt'%best_long_step)\n",
        "  for k in tnrange(1000, leave=False):\n",
        "    x, _ = ca1(x)\n",
        "  img = ca1.to_rgb(x)[0].permute(1, 2, 0).cpu()\n",
        "  imshow(zoom(img, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S885tTOUvOo"
      },
      "source": [
        "#@title Î¼NCA dynamics evolution video {vertical-output: true}\n",
        "with torch.no_grad():\n",
        "  ca1 = torch.load('ca_%05d.pt'%best_long_step)\n",
        "with LoopWriter('final_ca.mp4', fade_len=0.5) as vid, torch.no_grad():\n",
        "  x = seed_f(1, 256)\n",
        "  #x[:] = 0.0\n",
        "  #x[:,:,100, 100] = 1.0\n",
        "  for k in tnrange(400, leave=False):\n",
        "    img = ca.to_rgb(x)[0].permute(1, 2, 0).cpu()\n",
        "    vid.add(zoom(img, 2))\n",
        "    step_n = int(min(2**(k/30), 8))\n",
        "    for i in range(step_n):\n",
        "      x, _ = ca1(x)\n",
        "vid.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFQqDol-7QjP"
      },
      "source": [
        "# export 68-param to ShaderToy\n",
        "if len(filters) == 4:\n",
        "  S = 1000.0\n",
        "  w = (ca1.w[:,:,0,0]*S).round()\n",
        "  mat4 = 'mat4(%s)'%('%d,'*16)[:-1]\n",
        "  ws = [\"%.0e\"%(1/S), 'vec4(%d,%d,%d,%d)'%tuple(w[:,-1])]+[mat4%tuple(P.ravel()) for P in w.T[:-1].reshape(4, 4, 4)]\n",
        "  code = '''vec4 rule(vec4 s, vec4 p) {\n",
        "    return %s*(%s+\n",
        "      %s*s+\n",
        "      %s*p+\n",
        "      %s*abs(s)+\n",
        "      %s*abs(p));\n",
        "  }'''%tuple(ws)\n",
        "  print(code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGNcrf2ahe6s"
      },
      "source": [
        "# export 588-param to ShaderToy\n",
        "if len(filters) == 12:\n",
        "  w_scale = 500\n",
        "  with torch.no_grad():\n",
        "    w, b = ca1.w[:,:-1,0,0], ca1.w[:,-1,0,0]\n",
        "    weight = (w.T*w_scale).round().cpu()\n",
        "    bias = (b*w_scale).round().cpu()\n",
        "  \n",
        "  code = ['''\n",
        "  vec4 update(float band, vec4 y[6]) {\n",
        "    #define M mat4\n",
        "    #define F(i,_a,_b) {M a=_a,b=_b; vec4 yi=y[i]; dx+=G(0)+G(1)+G(2)+G(3);}\n",
        "    #define G(i) yi[i]*((yi[i]>0.0)?a[i]:b[i])\n",
        "    vec4 dx;''']\n",
        "  mat4_fmt = 'M(%s)'%','.join(['%d']*16)\n",
        "  for i, band in enumerate(np.split(weight, 3, 1)):\n",
        "    s = ' dx = vec4(%d,%d,%d,%d);'%tuple(bias[i*4:i*4+4])\n",
        "    code.append('  '+('if (band == 0.) {', '} else if (band == 1.) {', '} else {')[i] + s)\n",
        "    for j in range(CHN*2//4):\n",
        "      a = mat4_fmt % tuple(band[j*4:][:4].ravel())\n",
        "      b = mat4_fmt % tuple(band[j*4+CHN*2:][:4].ravel())\n",
        "      code.append(f'    F({j}, {a}, {b});')\n",
        "  code.append('''  }\n",
        "    #undef M\n",
        "    #undef F\n",
        "    #undef G\n",
        "    return dx/%.1f;\n",
        "  }'''%w_scale)\n",
        "  code = '\\n'.join(code) \n",
        "  print(len(code))\n",
        "  print(code)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}